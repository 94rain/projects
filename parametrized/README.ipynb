{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01077,
     "end_time": "2020-11-26T16:37:56.833837",
     "exception": false,
     "start_time": "2020-11-26T16:37:56.823067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "*Note:* You can run this from your computer (Jupyter or terminal), or use one of the\n",
    "hosted options:\n",
    "[![binder-logo](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/ploomber/projects/master?urlpath=%2Flab%2Ftree%2F../../projects-ploomber/parametrized%2FREADME.ipynb)\n",
    "[![deepnote-logo](https://deepnote.com/buttons/launch-in-deepnote-small.svg)](https://deepnote.com/launch?template=deepnote&url=https://github.com/ploomber/projects/blob/master/../../projects-ploomber/parametrized/README.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009997,
     "end_time": "2020-11-26T16:37:56.854394",
     "exception": false,
     "start_time": "2020-11-26T16:37:56.844397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Parametrized pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01042,
     "end_time": "2020-11-26T16:37:56.874440",
     "exception": false,
     "start_time": "2020-11-26T16:37:56.864020",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Often, pipelines perform the same operation over different subsets of the data. For example, say you are developing visualizations of economic data. You might want to generate the same charts for different countries. \n",
    "\n",
    "One way to approach the problem is to have a for loop on each pipeline task to process all countries you need. But such approach adds unnecessary complexity to our code, it's better to keep our logic simple (each task processes a single country) and take the iterative logic out of our pipeline.\n",
    "\n",
    "Ploomber allows you to do so using parametrized pipelines. Let's see a sample `pipeline.yaml`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010341,
     "end_time": "2020-11-26T16:37:56.894702",
     "exception": false,
     "start_time": "2020-11-26T16:37:56.884361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Spec (``pipeline.yaml``)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:37:56.919079Z",
     "iopub.status.busy": "2020-11-26T16:37:56.918392Z",
     "iopub.status.idle": "2020-11-26T16:37:58.098174Z",
     "shell.execute_reply": "2020-11-26T16:37:58.098889Z"
    },
    "papermill": {
     "duration": 1.194403,
     "end_time": "2020-11-26T16:37:58.099394",
     "exception": false,
     "start_time": "2020-11-26T16:37:56.904991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ploomberutils import display_file, filter_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:37:58.124427Z",
     "iopub.status.busy": "2020-11-26T16:37:58.123703Z",
     "iopub.status.idle": "2020-11-26T16:37:58.133676Z",
     "shell.execute_reply": "2020-11-26T16:37:58.134197Z"
    },
    "papermill": {
     "duration": 0.025262,
     "end_time": "2020-11-26T16:37:58.134399",
     "exception": false,
     "start_time": "2020-11-26T16:37:58.109137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "```yaml\n",
       "meta:\n",
       "  extract_product: False\n",
       "\n",
       "tasks:\n",
       "  - source: print.py\n",
       "    name: print\n",
       "    product:\n",
       "      nb: 'output/{{some_param}}/notebook.ipynb'\n",
       "    papermill_params:\n",
       "        log_output: True\n",
       "    params:\n",
       "      some_param: '{{some_param}}'\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_file('pipeline.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011342,
     "end_time": "2020-11-26T16:37:58.155779",
     "exception": false,
     "start_time": "2020-11-26T16:37:58.144437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The `pipeline.yaml` above has a placeholder called `some_param`. It is coming from a file called `env.yaml`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:37:58.179639Z",
     "iopub.status.busy": "2020-11-26T16:37:58.178831Z",
     "iopub.status.idle": "2020-11-26T16:37:58.181968Z",
     "shell.execute_reply": "2020-11-26T16:37:58.182410Z"
    },
    "papermill": {
     "duration": 0.017079,
     "end_time": "2020-11-26T16:37:58.182649",
     "exception": false,
     "start_time": "2020-11-26T16:37:58.165570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "```yaml\n",
       "some_param: default_value\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_file('env.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010261,
     "end_time": "2020-11-26T16:37:58.203886",
     "exception": false,
     "start_time": "2020-11-26T16:37:58.193625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "When assembling your pipeline, Ploomber looks for an `env.yaml` file. If found, all defined keys will be available to your pipeline definition. You can use these placeholders (placeholders are strings between double curly brackets) in any of the fields of your `pipeline.yaml` file.\n",
    "\n",
    "In our case, we are using it in two places. First, we are going to save the executed notebook in a folder with the value of `some_param`. This will allow you to keep copies of the generated output in a different folder depending on your parameter. Second, if we want to use the parameter in our code, we have to pass it to our tasks, all tasks take an optional `params` with arbitrary parameters.\n",
    "\n",
    "Let's see how the code looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:37:58.229222Z",
     "iopub.status.busy": "2020-11-26T16:37:58.228439Z",
     "iopub.status.idle": "2020-11-26T16:37:58.231824Z",
     "shell.execute_reply": "2020-11-26T16:37:58.232510Z"
    },
    "papermill": {
     "duration": 0.018213,
     "end_time": "2020-11-26T16:37:58.232966",
     "exception": false,
     "start_time": "2020-11-26T16:37:58.214753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "```py\n",
       "# + tags=[\"parameters\"]\n",
       "upstream = None\n",
       "product = None\n",
       "some_param = None\n",
       "\n",
       "# +\n",
       "print('some_param: ', some_param, ' type: ', type(some_param))\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_file('print.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011214,
     "end_time": "2020-11-26T16:37:58.254608",
     "exception": false,
     "start_time": "2020-11-26T16:37:58.243394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Our task is a Python script. This means parameters are passed as an injected cell at runtime. Let's see what happens if we build our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:37:58.284454Z",
     "iopub.status.busy": "2020-11-26T16:37:58.281562Z",
     "iopub.status.idle": "2020-11-26T16:38:02.094708Z",
     "shell.execute_reply": "2020-11-26T16:38:02.095319Z"
    },
    "papermill": {
     "duration": 3.828968,
     "end_time": "2020-11-26T16:38:02.095521",
     "exception": false,
     "start_time": "2020-11-26T16:37:58.266553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture captured\n",
    "%%sh\n",
    "ploomber build --force --log INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:38:02.125425Z",
     "iopub.status.busy": "2020-11-26T16:38:02.124561Z",
     "iopub.status.idle": "2020-11-26T16:38:02.127633Z",
     "shell.execute_reply": "2020-11-26T16:38:02.128109Z"
    },
    "papermill": {
     "duration": 0.021147,
     "end_time": "2020-11-26T16:38:02.128325",
     "exception": false,
     "start_time": "2020-11-26T16:38:02.107178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:papermill:some_param:  default_value  type:  <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "filter_output(captured, startswith='INFO:papermill:some_param')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010831,
     "end_time": "2020-11-26T16:38:02.151720",
     "exception": false,
     "start_time": "2020-11-26T16:38:02.140889",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We see that our param `some_param` is taking the default value (`default_value`) as defined in `env.yaml`. The command line interface is aware of any parameters, you can see them using the `--help` option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:38:02.179954Z",
     "iopub.status.busy": "2020-11-26T16:38:02.177334Z",
     "iopub.status.idle": "2020-11-26T16:38:04.485186Z",
     "shell.execute_reply": "2020-11-26T16:38:04.485740Z"
    },
    "papermill": {
     "duration": 2.323144,
     "end_time": "2020-11-26T16:38:04.485934",
     "exception": false,
     "start_time": "2020-11-26T16:38:02.162790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ploomber [-h] [--log LOG] [--entry-point ENTRY_POINT] [--force]\n",
      "                [--partially PARTIALLY] [--debug]\n",
      "                [--env--some_param ENV__SOME_PARAM]\n",
      "\n",
      "Build pipeline\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --log LOG, -l LOG     Enables logging to stdout at the specified level\n",
      "  --entry-point ENTRY_POINT, -e ENTRY_POINT\n",
      "                        Entry point(DAG), defaults to pipeline.yaml. Replaced\n",
      "                        if there is an ENTRY_POINT env variable defined\n",
      "  --force, -f           Force execution by ignoring status\n",
      "  --partially PARTIALLY, -p PARTIALLY\n",
      "                        Build a pipeline partially until certain task\n",
      "  --debug, -d           Drop a debugger session if an exception happens\n",
      "  --env--some_param ENV__SOME_PARAM\n",
      "                        Default: default_value\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "ploomber build --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01556,
     "end_time": "2020-11-26T16:38:04.513381",
     "exception": false,
     "start_time": "2020-11-26T16:38:04.497821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Apart from the default parameters from the `ploomber build` command, Ploomber automatically adds any parameters from `env.yaml`, we can easily override the default value, let's do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:38:04.545689Z",
     "iopub.status.busy": "2020-11-26T16:38:04.543177Z",
     "iopub.status.idle": "2020-11-26T16:38:08.235775Z",
     "shell.execute_reply": "2020-11-26T16:38:08.236458Z"
    },
    "papermill": {
     "duration": 3.710784,
     "end_time": "2020-11-26T16:38:08.236688",
     "exception": false,
     "start_time": "2020-11-26T16:38:04.525904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture captured\n",
    "%%sh\n",
    "ploomber build --force --env--some_param another_value --log INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:38:08.264779Z",
     "iopub.status.busy": "2020-11-26T16:38:08.264041Z",
     "iopub.status.idle": "2020-11-26T16:38:08.266682Z",
     "shell.execute_reply": "2020-11-26T16:38:08.267160Z"
    },
    "papermill": {
     "duration": 0.01896,
     "end_time": "2020-11-26T16:38:08.267401",
     "exception": false,
     "start_time": "2020-11-26T16:38:08.248441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:papermill:some_param:  another_value  type:  <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "filter_output(captured, startswith='INFO:papermill:some_param')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011867,
     "end_time": "2020-11-26T16:38:08.290962",
     "exception": false,
     "start_time": "2020-11-26T16:38:08.279095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We see that our task, effectively changed the value!\n",
    "\n",
    "Finally, let's see how the `output/` folder looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:38:08.320507Z",
     "iopub.status.busy": "2020-11-26T16:38:08.319650Z",
     "iopub.status.idle": "2020-11-26T16:38:08.359752Z",
     "shell.execute_reply": "2020-11-26T16:38:08.360426Z"
    },
    "papermill": {
     "duration": 0.058079,
     "end_time": "2020-11-26T16:38:08.360704",
     "exception": false,
     "start_time": "2020-11-26T16:38:08.302625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output\n",
      "├── another_value\n",
      "│   ├── notebook.ipynb\n",
      "│   └── notebook.ipynb.source\n",
      "└── default_value\n",
      "    ├── notebook.ipynb\n",
      "    └── notebook.ipynb.source\n",
      "\n",
      "2 directories, 4 files\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "tree output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012119,
     "end_time": "2020-11-26T16:38:08.384924",
     "exception": false,
     "start_time": "2020-11-26T16:38:08.372805",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We have separate folders for each parameter, this helps keep things organized and takes the looping logic out of our pipeline.\n",
    "\n",
    "\n",
    "### Tips\n",
    "\n",
    "* This example uses a Python script as a task, in SQL pipeline, you can achieve the same effect (keeping output separate) by using the placeholder either in the product's schema or as a prefix in the table/view name\n",
    "* If the parameter takes a lot of different values and you want to run your pipeline using all of them, calling them by hand might get tedious. You have two options 1) write a  bash script that calls the CLI with different value parameters or 2) Use the Python API (everything that the CLI can do, you can do with Python directly), take a look at the `DAGSpec` documentation\n",
    "* Parametrized `pipeline.yaml` files are a great way to simplify task's logic but don't overdo it. If you find yourself adding too many parameters, it's a better idea to use the Python API directly. Factory function are the right pattern for highly customized pipeline construction\n",
    "* Given that the two pipelines are completely independent we could even run them in parallel to speed things up\n",
    "\n",
    "\n",
    "## Factory functions\n",
    "\n",
    "Parametrization is straightforward when using a factory function. If your\n",
    "factory takes parameters, they'll also be available in the command\n",
    "line interface. Types are inferred from [type hints](https://docs.python.org/3/library/typing.html). Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:38:08.413887Z",
     "iopub.status.busy": "2020-11-26T16:38:08.413088Z",
     "iopub.status.idle": "2020-11-26T16:38:08.416738Z",
     "shell.execute_reply": "2020-11-26T16:38:08.417233Z"
    },
    "papermill": {
     "duration": 0.020677,
     "end_time": "2020-11-26T16:38:08.417466",
     "exception": false,
     "start_time": "2020-11-26T16:38:08.396789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "```py\n",
       "from ploomber import DAG\n",
       "\n",
       "\n",
       "def make(param: str, another: int = 10):\n",
       "    dag = DAG()\n",
       "    # add tasks to your pipeline...\n",
       "    return dag\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_file('factory.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011844,
     "end_time": "2020-11-26T16:38:08.441597",
     "exception": false,
     "start_time": "2020-11-26T16:38:08.429753",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Our function takes two parameters: `param` and `another`. Parameters with no default values (`param`) are converted to positional arguments and function parameters with default values are converted\n",
    "to optional parameters (`another`). To see the exact auto-generated API, you can use the `--help` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:38:08.471106Z",
     "iopub.status.busy": "2020-11-26T16:38:08.468432Z",
     "iopub.status.idle": "2020-11-26T16:38:10.648275Z",
     "shell.execute_reply": "2020-11-26T16:38:10.647727Z"
    },
    "papermill": {
     "duration": 2.195338,
     "end_time": "2020-11-26T16:38:10.648484",
     "exception": false,
     "start_time": "2020-11-26T16:38:08.453146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ploomber [-h] [--log LOG] [--entry-point ENTRY_POINT] [--force]\n",
      "                [--partially PARTIALLY] [--debug] [--another ANOTHER]\n",
      "                param\n",
      "\n",
      "Build pipeline\n",
      "\n",
      "positional arguments:\n",
      "  param\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --log LOG, -l LOG     Enables logging to stdout at the specified level\n",
      "  --entry-point ENTRY_POINT, -e ENTRY_POINT\n",
      "                        Entry point(DAG), defaults to pipeline.yaml. Replaced\n",
      "                        if there is an ENTRY_POINT env variable defined\n",
      "  --force, -f           Force execution by ignoring status\n",
      "  --partially PARTIALLY, -p PARTIALLY\n",
      "                        Build a pipeline partially until certain task\n",
      "  --debug, -d           Drop a debugger session if an exception happens\n",
      "  --another ANOTHER\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "ploomber build --entry-point factory.make --help"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15.327709,
   "end_time": "2020-11-26T16:38:11.140281",
   "environment_variables": {},
   "exception": null,
   "input_path": "/var/folders/3h/_lvh_w_x5g30rrjzb_xnn2j80000gq/T/tmpd94lfw5m.ipynb",
   "output_path": "../../projects-ploomber/parametrized/README.ipynb",
   "parameters": {
    "product": "../../projects-ploomber/parametrized/README.ipynb"
   },
   "start_time": "2020-11-26T16:37:55.812572",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
