{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.010701,
     "end_time": "2020-11-26T18:20:41.662448",
     "exception": false,
     "start_time": "2020-11-26T18:20:41.651747",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "*Note:* You can run this from your computer (Jupyter or terminal), or use one of the\n",
    "hosted options:\n",
    "[![binder-logo](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/ploomber/binder-env/main?urlpath=git-pull%3Frepo%3Dhttps%253A%252F%252Fgithub.com%252Fploomber%252Fprojects%26urlpath%3Dlab%252Ftree%252Fprojects%252Fspec-api-sql%252FREADME.ipynb%26branch%3Dmaster)\n",
    "[![deepnote-logo](https://deepnote.com/buttons/launch-in-deepnote-small.svg)](https://deepnote.com/launch?template=deepnote&url=https://github.com/ploomber/projects/blob/master/spec-api-sql/README.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007197,
     "end_time": "2020-11-26T18:20:41.676469",
     "exception": false,
     "start_time": "2020-11-26T18:20:41.669272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SQL/Python pipeline example\n",
    "\n",
    "This demo showcases the spec API that allows you to write pipelines using YAML files so you can focus on the Data Science and not dealing which complex task dependencies nor managing database connections.\n",
    "\n",
    "Let's take a look at the pipeline definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T18:20:41.702168Z",
     "iopub.status.busy": "2020-11-26T18:20:41.701456Z",
     "iopub.status.idle": "2020-11-26T18:20:41.704886Z",
     "shell.execute_reply": "2020-11-26T18:20:41.705372Z"
    },
    "papermill": {
     "duration": 0.022322,
     "end_time": "2020-11-26T18:20:41.705715",
     "exception": false,
     "start_time": "2020-11-26T18:20:41.683393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```yaml\n",
       "meta:\n",
       "  extract_product: False\n",
       "\n",
       "  product_default_class:\n",
       "    SQLScript: SQLiteRelation\n",
       "\n",
       "  jupyter_hot_reload: True\n",
       "\n",
       "config:\n",
       "  hot_reload: True\n",
       "\n",
       "clients:\n",
       "  # tasks\n",
       "  SQLScript: config.get_client\n",
       "  SQLDump: config.get_client\n",
       "  # products\n",
       "  SQLiteRelation: config.get_client\n",
       "\n",
       "tasks:\n",
       "  - source: filter_sales.sql\n",
       "    product: [filtered_sales, table]\n",
       "    name: filter_sales\n",
       "\n",
       "  - source: group_sales.sql\n",
       "    product: [grouped_sales, table]\n",
       "    name: group_sales\n",
       "\n",
       "  - source: filter_prices.sql\n",
       "    product: [filtered_prices, table]\n",
       "    name: filter_prices\n",
       "\n",
       "  - source: join.sql\n",
       "    product: [joined, table]\n",
       "    name: join\n",
       "\n",
       "  - class: SQLDump\n",
       "    source: join_dump.sql\n",
       "    product: output/joined_data.csv\n",
       "    name: join_dump\n",
       "    chunksize: null\n",
       "\n",
       "  - source: plot.py\n",
       "    product: output/plot.html```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown('```yaml\\n{}```'.format(Path('pipeline.yaml').read_text()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.006791,
     "end_time": "2020-11-26T18:20:41.719799",
     "exception": false,
     "start_time": "2020-11-26T18:20:41.713008",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The first two sections configure our pipeline, the `tasks` section is the actual pipeline definition. Each element defines a task, we see that we have a few SQL transformations, then we dump a table to a CSV file and we produce an HTML report at the end. The order here doesn't matter, the source code itself declares its own upstream dependencies and Ploomber extracts them to execute your pipeline.\n",
    "\n",
    "Let's take a look at one of the SQL files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T18:20:41.738080Z",
     "iopub.status.busy": "2020-11-26T18:20:41.737219Z",
     "iopub.status.idle": "2020-11-26T18:20:41.741382Z",
     "shell.execute_reply": "2020-11-26T18:20:41.741822Z"
    },
    "papermill": {
     "duration": 0.015393,
     "end_time": "2020-11-26T18:20:41.742054",
     "exception": false,
     "start_time": "2020-11-26T18:20:41.726661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```yaml\n",
       "-- this placeholder will be replaced at runtime\n",
       "DROP TABLE IF EXISTS {{product}};\n",
       "\n",
       "CREATE TABLE {{product}} AS\n",
       "SELECT product_id, count * price AS revenue\n",
       "-- declare dependencies using the name (or source if no name was declared)\n",
       "-- of the task that should run first\n",
       "FROM {{upstream['group_sales']}}\n",
       "JOIN {{upstream['filter_prices']}}\n",
       "USING (product_id);\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Markdown('```yaml\\n{}```'.format(Path('join.sql').read_text()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007186,
     "end_time": "2020-11-26T18:20:41.756664",
     "exception": false,
     "start_time": "2020-11-26T18:20:41.749478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Alright, let's get going, we can run our pipeline with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T18:20:41.775818Z",
     "iopub.status.busy": "2020-11-26T18:20:41.774225Z",
     "iopub.status.idle": "2020-11-26T18:20:47.853232Z",
     "shell.execute_reply": "2020-11-26T18:20:47.853867Z"
    },
    "lines_to_next_cell": 0,
    "papermill": {
     "duration": 6.090602,
     "end_time": "2020-11-26T18:20:47.854095",
     "exception": false,
     "start_time": "2020-11-26T18:20:41.763493",
     "status": "completed"
    },
    "tags": [
     "bash"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name           Ran?      Elapsed (s)    Percentage\n",
      "-------------  ------  -------------  ------------\n",
      "filter_prices  True         0.002728     0.0652201\n",
      "filter_sales   True         0.001611     0.0385152\n",
      "group_sales    True         0.001376     0.0328969\n",
      "join           True         0.001197     0.0286175\n",
      "join_dump      True         0.00167      0.0399258\n",
      "plot.py        True         4.17418     99.7948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 6818.16it/s]\n",
      "Building task \"plot.py\":   0%|          | 0/6 [00:00<?, ?it/s]  \n",
      "Executing:   0%|          | 0/4 [00:00<?, ?cell/s]\u001b[A\n",
      "Executing:  25%|██▌       | 1/4 [00:01<00:04,  1.66s/cell]\u001b[A\n",
      "Executing: 100%|██████████| 4/4 [00:03<00:00,  1.30cell/s]\n",
      "Building task \"plot.py\": 100%|██████████| 6/6 [00:04<00:00,  1.43it/s]\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "ploomber build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0083,
     "end_time": "2020-11-26T18:20:47.870475",
     "exception": false,
     "start_time": "2020-11-26T18:20:47.862175",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "That's it. We just build our pipeline. Let's try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T18:20:47.892519Z",
     "iopub.status.busy": "2020-11-26T18:20:47.891817Z",
     "iopub.status.idle": "2020-11-26T18:20:49.869333Z",
     "shell.execute_reply": "2020-11-26T18:20:49.869777Z"
    },
    "papermill": {
     "duration": 1.991075,
     "end_time": "2020-11-26T18:20:49.870036",
     "exception": false,
     "start_time": "2020-11-26T18:20:47.878961",
     "status": "completed"
    },
    "tags": [
     "bash"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name           Ran?      Elapsed (s)    Percentage\n",
      "-------------  ------  -------------  ------------\n",
      "filter_prices  False               0             0\n",
      "filter_sales   False               0             0\n",
      "group_sales    False               0             0\n",
      "join           False               0             0\n",
      "join_dump      False               0             0\n",
      "plot.py        False               0             0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 7092.96it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "ploomber build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009499,
     "end_time": "2020-11-26T18:20:49.888275",
     "exception": false,
     "start_time": "2020-11-26T18:20:49.878776",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This time it finished real quick because there is nothing to do, nothing has changed.\n",
    "\n",
    "Let's now modify one of the tasks to see what happens (make sure you save changes):\n",
    "\n",
    "[Click here to open plot.py](plot.py)\n",
    "\n",
    "Also try modifying any of the SQL scripts:\n",
    "\n",
    "[Click here to go to the spec folder](.)\n",
    "\n",
    "Let's build again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T18:20:49.911535Z",
     "iopub.status.busy": "2020-11-26T18:20:49.910724Z",
     "iopub.status.idle": "2020-11-26T18:20:51.768713Z",
     "shell.execute_reply": "2020-11-26T18:20:51.769192Z"
    },
    "papermill": {
     "duration": 1.87283,
     "end_time": "2020-11-26T18:20:51.769425",
     "exception": false,
     "start_time": "2020-11-26T18:20:49.896595",
     "status": "completed"
    },
    "tags": [
     "bash"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name           Ran?      Elapsed (s)    Percentage\n",
      "-------------  ------  -------------  ------------\n",
      "filter_prices  False               0             0\n",
      "filter_sales   False               0             0\n",
      "group_sales    False               0             0\n",
      "join           False               0             0\n",
      "join_dump      False               0             0\n",
      "plot.py        False               0             0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 8032.50it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "ploomber build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009842,
     "end_time": "2020-11-26T18:20:51.788510",
     "exception": false,
     "start_time": "2020-11-26T18:20:51.778668",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Depending on your changes, Ploomber will determine which tasks to run again and which ones to skip.\n",
    "\n",
    "The final output of our pipeline is a report, [let's see it](output/plot.html).\n",
    "\n",
    "That's it! Ploomber makes it very simple to manage your data workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009278,
     "end_time": "2020-11-26T18:20:51.808389",
     "exception": false,
     "start_time": "2020-11-26T18:20:51.799111",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Where to go from here\n",
    "\n",
    "[`etl/`](../etl/README.ipynb) contains a more complete SQL example."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "main_language": "bash",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.236722,
   "end_time": "2020-11-26T18:20:52.079929",
   "environment_variables": {},
   "exception": null,
   "input_path": "/var/folders/3h/_lvh_w_x5g30rrjzb_xnn2j80000gq/T/tmpfsnf6d2d.ipynb",
   "output_path": "spec-api-sql/README.ipynb",
   "parameters": {
    "product": "spec-api-sql/README.ipynb"
   },
   "start_time": "2020-11-26T18:20:40.843207",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
