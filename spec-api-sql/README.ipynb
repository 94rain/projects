{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008565,
     "end_time": "2020-11-26T17:51:43.953529",
     "exception": false,
     "start_time": "2020-11-26T17:51:43.944964",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "*Note:* You can run this from your computer (Jupyter or terminal), or use one of the\n",
    "hosted options:\n",
    "[![binder-logo](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/ploomber/binder-env/main?urlpath=git-pull%3Frepo%3Dhttps%253A%252F%252Fgithub.com%252Fploomber%252Fprojects%26urlpath%3Dlab%252Ftree%252Fprojects%252Fspec-api-sql%252FREADME.ipynb%26branch%3Dmaster)\n",
    "[![deepnote-logo](https://deepnote.com/buttons/launch-in-deepnote-small.svg)](https://deepnote.com/launch?template=deepnote&url=https://github.com/ploomber/projects/blob/master/spec-api-sql/README.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007528,
     "end_time": "2020-11-26T17:51:43.967188",
     "exception": false,
     "start_time": "2020-11-26T17:51:43.959660",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SQL/Python pipeline example\n",
    "\n",
    "This demo showcases the spec API that allows you to write pipelines using YAML files so you can focus on the Data Science and not dealing which complex task dependencies nor managing database connections.\n",
    "\n",
    "Let's take a look at the pipeline definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:51:43.984044Z",
     "iopub.status.busy": "2020-11-26T17:51:43.983350Z",
     "iopub.status.idle": "2020-11-26T17:51:43.992175Z",
     "shell.execute_reply": "2020-11-26T17:51:43.992639Z"
    },
    "papermill": {
     "duration": 0.020022,
     "end_time": "2020-11-26T17:51:43.992949",
     "exception": false,
     "start_time": "2020-11-26T17:51:43.972927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```yaml\n",
       "meta:\n",
       "  extract_product: False\n",
       "\n",
       "  product_default_class:\n",
       "    SQLScript: SQLiteRelation\n",
       "\n",
       "  jupyter_hot_reload: True\n",
       "\n",
       "config:\n",
       "  hot_reload: True\n",
       "\n",
       "clients:\n",
       "  # tasks\n",
       "  SQLScript: config.get_client\n",
       "  SQLDump: config.get_client\n",
       "  # products\n",
       "  SQLiteRelation: config.get_client\n",
       "\n",
       "tasks:\n",
       "  - source: filter_sales.sql\n",
       "    product: [filtered_sales, table]\n",
       "    name: filter_sales\n",
       "\n",
       "  - source: group_sales.sql\n",
       "    product: [grouped_sales, table]\n",
       "    name: group_sales\n",
       "\n",
       "  - source: filter_prices.sql\n",
       "    product: [filtered_prices, table]\n",
       "    name: filter_prices\n",
       "\n",
       "  - source: join.sql\n",
       "    product: [joined, table]\n",
       "    name: join\n",
       "\n",
       "  - class: SQLDump\n",
       "    source: join_dump.sql\n",
       "    product: output/joined_data.csv\n",
       "    name: join_dump\n",
       "    chunksize: null\n",
       "\n",
       "  - source: plot.py\n",
       "    product: output/plot.html```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown('```yaml\\n{}```'.format(Path('pipeline.yaml').read_text()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.006385,
     "end_time": "2020-11-26T17:51:44.005883",
     "exception": false,
     "start_time": "2020-11-26T17:51:43.999498",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The first two sections configure our pipeline, the `tasks` section is the actual pipeline definition. Each element defines a task, we see that we have a few SQL transformations, then we dump a table to a CSV file and we produce an HTML report at the end. The order here doesn't matter, the source code itself declares its own upstream dependencies and Ploomber extracts them to execute your pipeline.\n",
    "\n",
    "Let's take a look at one of the SQL files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:51:44.022945Z",
     "iopub.status.busy": "2020-11-26T17:51:44.022100Z",
     "iopub.status.idle": "2020-11-26T17:51:44.025764Z",
     "shell.execute_reply": "2020-11-26T17:51:44.026427Z"
    },
    "papermill": {
     "duration": 0.013876,
     "end_time": "2020-11-26T17:51:44.026675",
     "exception": false,
     "start_time": "2020-11-26T17:51:44.012799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```yaml\n",
       "-- this placeholder will be replaced at runtime\n",
       "DROP TABLE IF EXISTS {{product}};\n",
       "\n",
       "CREATE TABLE {{product}} AS\n",
       "SELECT product_id, count * price AS revenue\n",
       "-- declare dependencies using the name (or source if no name was declared)\n",
       "-- of the task that should run first\n",
       "FROM {{upstream['group_sales']}}\n",
       "JOIN {{upstream['filter_prices']}}\n",
       "USING (product_id);\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown('```yaml\\n{}```'.format(Path('join.sql').read_text()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.00639,
     "end_time": "2020-11-26T17:51:44.039389",
     "exception": false,
     "start_time": "2020-11-26T17:51:44.032999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Alright, let's get going, we can run our pipeline with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:51:44.056639Z",
     "iopub.status.busy": "2020-11-26T17:51:44.055995Z",
     "iopub.status.idle": "2020-11-26T17:51:46.722838Z",
     "shell.execute_reply": "2020-11-26T17:51:46.723453Z"
    },
    "lines_to_next_cell": 0,
    "papermill": {
     "duration": 2.677789,
     "end_time": "2020-11-26T17:51:46.723756",
     "exception": false,
     "start_time": "2020-11-26T17:51:44.045967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 6/6 [00:00<00:00, 5981.89it/s]\r\n",
      "Building task \"filter_sales\": 100%|██████████████| 6/6 [00:00<00:00, 731.35it/s]\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/dag/DAG.py\", line 442, in _build\r\n",
      "    task_reports = self._executor(dag=self,\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 134, in __call__\r\n",
      "    raise DAGBuildError('DAG build failed, the following '\r\n",
      "ploomber.exceptions.DAGBuildError: DAG build failed, the following tasks crashed (corresponding downstream tasks aborted execution):\r\n",
      "* SQLScript: filter_prices -> SQLiteRelation(filtered_prices)\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/Task.py\", line 456, in _build\r\n",
      "    res = self._run()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/Task.py\", line 545, in _run\r\n",
      "    self.run()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/sql.py\", line 60, in run\r\n",
      "    return self.client.execute(str(self.source))\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/clients/db.py\", line 162, in execute\r\n",
      "    cur.execute(command)\r\n",
      "sqlite3.OperationalError: no such table: prices\r\n",
      "\r\n",
      "The above exception was the direct cause of the following exception:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 180, in catch_exceptions\r\n",
      "    fn()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 159, in __call__\r\n",
      "    return self.fn(**self.kwargs)\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 164, in catch_warnings\r\n",
      "    result = fn()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 159, in __call__\r\n",
      "    return self.fn(**self.kwargs)\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 227, in build_in_subprocess\r\n",
      "    report, meta = task._build(**build_kwargs)\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/Task.py\", line 469, in _build\r\n",
      "    raise TaskBuildError(msg) from e\r\n",
      "ploomber.exceptions.TaskBuildError: Error building task \"filter_prices\"\r\n",
      "\r\n",
      "\r\n",
      "--------------------------------------------------------------------------------\r\n",
      "--------------------------------------------------------------------------------\r\n",
      "\r\n",
      "* SQLScript: filter_sales -> SQLiteRelation(filtered_sales)\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/Task.py\", line 456, in _build\r\n",
      "    res = self._run()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/Task.py\", line 545, in _run\r\n",
      "    self.run()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/sql.py\", line 60, in run\r\n",
      "    return self.client.execute(str(self.source))\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/clients/db.py\", line 162, in execute\r\n",
      "    cur.execute(command)\r\n",
      "sqlite3.OperationalError: no such table: sales\r\n",
      "\r\n",
      "The above exception was the direct cause of the following exception:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 180, in catch_exceptions\r\n",
      "    fn()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 159, in __call__\r\n",
      "    return self.fn(**self.kwargs)\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 164, in catch_warnings\r\n",
      "    result = fn()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 159, in __call__\r\n",
      "    return self.fn(**self.kwargs)\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 227, in build_in_subprocess\r\n",
      "    report, meta = task._build(**build_kwargs)\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/Task.py\", line 469, in _build\r\n",
      "    raise TaskBuildError(msg) from e\r\n",
      "ploomber.exceptions.TaskBuildError: Error building task \"filter_sales\"\r\n",
      "\r\n",
      "\r\n",
      "The above exception was the direct cause of the following exception:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/Edu/miniconda3/envs/ploomber/bin/ploomber\", line 33, in <module>\r\n",
      "    sys.exit(load_entry_point('ploomber', 'console_scripts', 'ploomber')())\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/cli/cli.py\", line 173, in cmd_router\r\n",
      "    fn()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/cli/build.py\", line 36, in main\r\n",
      "    report = dag.build(force=args.force, debug=args.debug)\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/dag/DAG.py\", line 414, in build\r\n",
      "    report = callable_()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/dag/DAG.py\", line 513, in _build\r\n",
      "    raise DAGBuildError(\r\n",
      "ploomber.exceptions.DAGBuildError: Failed to build DAG DAG(\"No name\")\r\n"
     ]
    }
   ],
   "source": [
    "! ploomber build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007528,
     "end_time": "2020-11-26T17:51:46.740558",
     "exception": false,
     "start_time": "2020-11-26T17:51:46.733030",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "That's it. We just build our pipeline. Let's try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:51:46.760982Z",
     "iopub.status.busy": "2020-11-26T17:51:46.760233Z",
     "iopub.status.idle": "2020-11-26T17:51:49.326852Z",
     "shell.execute_reply": "2020-11-26T17:51:49.327474Z"
    },
    "papermill": {
     "duration": 2.57947,
     "end_time": "2020-11-26T17:51:49.327777",
     "exception": false,
     "start_time": "2020-11-26T17:51:46.748307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 6/6 [00:00<00:00, 5813.31it/s]\r\n",
      "Building task \"filter_sales\": 100%|█████████████| 6/6 [00:00<00:00, 1303.25it/s]\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/dag/DAG.py\", line 442, in _build\r\n",
      "    task_reports = self._executor(dag=self,\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 134, in __call__\r\n",
      "    raise DAGBuildError('DAG build failed, the following '\r\n",
      "ploomber.exceptions.DAGBuildError: DAG build failed, the following tasks crashed (corresponding downstream tasks aborted execution):\r\n",
      "* SQLScript: filter_prices -> SQLiteRelation(filtered_prices)\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/Task.py\", line 456, in _build\r\n",
      "    res = self._run()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/Task.py\", line 545, in _run\r\n",
      "    self.run()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/sql.py\", line 60, in run\r\n",
      "    return self.client.execute(str(self.source))\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/clients/db.py\", line 162, in execute\r\n",
      "    cur.execute(command)\r\n",
      "sqlite3.OperationalError: no such table: prices\r\n",
      "\r\n",
      "The above exception was the direct cause of the following exception:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 180, in catch_exceptions\r\n",
      "    fn()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 159, in __call__\r\n",
      "    return self.fn(**self.kwargs)\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 164, in catch_warnings\r\n",
      "    result = fn()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 159, in __call__\r\n",
      "    return self.fn(**self.kwargs)\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 227, in build_in_subprocess\r\n",
      "    report, meta = task._build(**build_kwargs)\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/Task.py\", line 469, in _build\r\n",
      "    raise TaskBuildError(msg) from e\r\n",
      "ploomber.exceptions.TaskBuildError: Error building task \"filter_prices\"\r\n",
      "\r\n",
      "\r\n",
      "--------------------------------------------------------------------------------\r\n",
      "--------------------------------------------------------------------------------\r\n",
      "\r\n",
      "* SQLScript: filter_sales -> SQLiteRelation(filtered_sales)\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/Task.py\", line 456, in _build\r\n",
      "    res = self._run()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/Task.py\", line 545, in _run\r\n",
      "    self.run()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/sql.py\", line 60, in run\r\n",
      "    return self.client.execute(str(self.source))\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/clients/db.py\", line 162, in execute\r\n",
      "    cur.execute(command)\r\n",
      "sqlite3.OperationalError: no such table: sales\r\n",
      "\r\n",
      "The above exception was the direct cause of the following exception:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 180, in catch_exceptions\r\n",
      "    fn()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 159, in __call__\r\n",
      "    return self.fn(**self.kwargs)\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 164, in catch_warnings\r\n",
      "    result = fn()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 159, in __call__\r\n",
      "    return self.fn(**self.kwargs)\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 227, in build_in_subprocess\r\n",
      "    report, meta = task._build(**build_kwargs)\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/Task.py\", line 469, in _build\r\n",
      "    raise TaskBuildError(msg) from e\r\n",
      "ploomber.exceptions.TaskBuildError: Error building task \"filter_sales\"\r\n",
      "\r\n",
      "\r\n",
      "The above exception was the direct cause of the following exception:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/Edu/miniconda3/envs/ploomber/bin/ploomber\", line 33, in <module>\r\n",
      "    sys.exit(load_entry_point('ploomber', 'console_scripts', 'ploomber')())\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/cli/cli.py\", line 173, in cmd_router\r\n",
      "    fn()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/cli/build.py\", line 36, in main\r\n",
      "    report = dag.build(force=args.force, debug=args.debug)\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/dag/DAG.py\", line 414, in build\r\n",
      "    report = callable_()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/dag/DAG.py\", line 513, in _build\r\n",
      "    raise DAGBuildError(\r\n",
      "ploomber.exceptions.DAGBuildError: Failed to build DAG DAG(\"No name\")\r\n"
     ]
    }
   ],
   "source": [
    "! ploomber build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012785,
     "end_time": "2020-11-26T17:51:49.350730",
     "exception": false,
     "start_time": "2020-11-26T17:51:49.337945",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This time it finished real quick because there is nothing to do, nothing has changed.\n",
    "\n",
    "Let's now modify one of the tasks to see what happens (make sure you save changes):\n",
    "\n",
    "[Click here to open plot.py](plot.py)\n",
    "\n",
    "Also try modifying any of the SQL scripts:\n",
    "\n",
    "[Click here to go to the spec folder](.)\n",
    "\n",
    "Let's build again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:51:49.372626Z",
     "iopub.status.busy": "2020-11-26T17:51:49.372022Z",
     "iopub.status.idle": "2020-11-26T17:51:51.914507Z",
     "shell.execute_reply": "2020-11-26T17:51:51.915295Z"
    },
    "papermill": {
     "duration": 2.556404,
     "end_time": "2020-11-26T17:51:51.915611",
     "exception": false,
     "start_time": "2020-11-26T17:51:49.359207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 6/6 [00:00<00:00, 5976.21it/s]\r\n",
      "Building task \"filter_sales\": 100%|█████████████| 6/6 [00:00<00:00, 1273.38it/s]\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/dag/DAG.py\", line 442, in _build\r\n",
      "    task_reports = self._executor(dag=self,\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 134, in __call__\r\n",
      "    raise DAGBuildError('DAG build failed, the following '\r\n",
      "ploomber.exceptions.DAGBuildError: DAG build failed, the following tasks crashed (corresponding downstream tasks aborted execution):\r\n",
      "* SQLScript: filter_prices -> SQLiteRelation(filtered_prices)\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/Task.py\", line 456, in _build\r\n",
      "    res = self._run()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/Task.py\", line 545, in _run\r\n",
      "    self.run()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/sql.py\", line 60, in run\r\n",
      "    return self.client.execute(str(self.source))\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/clients/db.py\", line 162, in execute\r\n",
      "    cur.execute(command)\r\n",
      "sqlite3.OperationalError: no such table: prices\r\n",
      "\r\n",
      "The above exception was the direct cause of the following exception:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 180, in catch_exceptions\r\n",
      "    fn()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 159, in __call__\r\n",
      "    return self.fn(**self.kwargs)\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 164, in catch_warnings\r\n",
      "    result = fn()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 159, in __call__\r\n",
      "    return self.fn(**self.kwargs)\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 227, in build_in_subprocess\r\n",
      "    report, meta = task._build(**build_kwargs)\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/Task.py\", line 469, in _build\r\n",
      "    raise TaskBuildError(msg) from e\r\n",
      "ploomber.exceptions.TaskBuildError: Error building task \"filter_prices\"\r\n",
      "\r\n",
      "\r\n",
      "--------------------------------------------------------------------------------\r\n",
      "--------------------------------------------------------------------------------\r\n",
      "\r\n",
      "* SQLScript: filter_sales -> SQLiteRelation(filtered_sales)\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/Task.py\", line 456, in _build\r\n",
      "    res = self._run()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/Task.py\", line 545, in _run\r\n",
      "    self.run()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/sql.py\", line 60, in run\r\n",
      "    return self.client.execute(str(self.source))\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/clients/db.py\", line 162, in execute\r\n",
      "    cur.execute(command)\r\n",
      "sqlite3.OperationalError: no such table: sales\r\n",
      "\r\n",
      "The above exception was the direct cause of the following exception:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 180, in catch_exceptions\r\n",
      "    fn()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 159, in __call__\r\n",
      "    return self.fn(**self.kwargs)\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 164, in catch_warnings\r\n",
      "    result = fn()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 159, in __call__\r\n",
      "    return self.fn(**self.kwargs)\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/executors/serial.py\", line 227, in build_in_subprocess\r\n",
      "    report, meta = task._build(**build_kwargs)\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/tasks/Task.py\", line 469, in _build\r\n",
      "    raise TaskBuildError(msg) from e\r\n",
      "ploomber.exceptions.TaskBuildError: Error building task \"filter_sales\"\r\n",
      "\r\n",
      "\r\n",
      "The above exception was the direct cause of the following exception:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/Edu/miniconda3/envs/ploomber/bin/ploomber\", line 33, in <module>\r\n",
      "    sys.exit(load_entry_point('ploomber', 'console_scripts', 'ploomber')())\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/cli/cli.py\", line 173, in cmd_router\r\n",
      "    fn()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/cli/build.py\", line 36, in main\r\n",
      "    report = dag.build(force=args.force, debug=args.debug)\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/dag/DAG.py\", line 414, in build\r\n",
      "    report = callable_()\r\n",
      "  File \"/Users/Edu/dev/ploomber/src/ploomber/dag/DAG.py\", line 513, in _build\r\n",
      "    raise DAGBuildError(\r\n",
      "ploomber.exceptions.DAGBuildError: Failed to build DAG DAG(\"No name\")\r\n"
     ]
    }
   ],
   "source": [
    "! ploomber build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.009054,
     "end_time": "2020-11-26T17:51:51.935456",
     "exception": false,
     "start_time": "2020-11-26T17:51:51.926402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Depending on your changes, Ploomber will determine which tasks to run again and which ones to skip.\n",
    "\n",
    "The final output of our pipeline is a report, [let's see it](output/plot.html).\n",
    "\n",
    "That's it! Ploomber makes it very simple to manage your data workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008993,
     "end_time": "2020-11-26T17:51:51.953152",
     "exception": false,
     "start_time": "2020-11-26T17:51:51.944159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Where to go from here\n",
    "\n",
    "[`etl/`](../etl/README.ipynb) contains a more complete SQL example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.008833,
     "end_time": "2020-11-26T17:51:51.970570",
     "exception": false,
     "start_time": "2020-11-26T17:51:51.961737",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T17:51:51.991678Z",
     "iopub.status.busy": "2020-11-26T17:51:51.990883Z",
     "iopub.status.idle": "2020-11-26T17:51:51.993325Z",
     "shell.execute_reply": "2020-11-26T17:51:51.993786Z"
    },
    "papermill": {
     "duration": 0.014871,
     "end_time": "2020-11-26T17:51:51.994004",
     "exception": false,
     "start_time": "2020-11-26T17:51:51.979133",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "product = \"spec-api-sql/README.ipynb\"\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "sh",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10.049079,
   "end_time": "2020-11-26T17:51:53.186840",
   "environment_variables": {},
   "exception": null,
   "input_path": "/var/folders/3h/_lvh_w_x5g30rrjzb_xnn2j80000gq/T/tmp1mf6yw4x.ipynb",
   "output_path": "spec-api-sql/README.ipynb",
   "parameters": {
    "product": "spec-api-sql/README.ipynb"
   },
   "start_time": "2020-11-26T17:51:43.137761",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
