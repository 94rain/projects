{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022364,
     "end_time": "2020-11-26T16:37:50.482485",
     "exception": false,
     "start_time": "2020-11-26T16:37:50.460121",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "*Note:* You can run this from your computer (Jupyter or terminal), or use one of the\n",
    "hosted options:\n",
    "[![binder-logo](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/ploomber/projects/master?urlpath=%2Flab%2Ftree%2F../../projects-ploomber/sql-templating%2FREADME.ipynb)\n",
    "[![deepnote-logo](https://deepnote.com/buttons/launch-in-deepnote-small.svg)](https://deepnote.com/launch?template=deepnote&url=https://github.com/ploomber/projects/blob/master/../../projects-ploomber/sql-templating/README.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.006498,
     "end_time": "2020-11-26T16:37:50.495866",
     "exception": false,
     "start_time": "2020-11-26T16:37:50.489368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SQL templating\n",
    "\n",
    "## Basic templating\n",
    "\n",
    "SQL templating is a powerful way to make your SQL scripts more concise. It works by using a templating language (Ploomber uses [jinja](https://github.com/pallets/jinja)) to generate SQL code on the fly.\n",
    "\n",
    "If you've followed the SQL pipelines tutorial in the *Get started* section, you've already used SQL templating. Let's take a look at the structure of a SQL script in Ploomber:\n",
    "\n",
    "```postgresql\n",
    "{% set product = SQLRelation(['my_schema', 'my_table', 'table']) %}\n",
    "\n",
    "DROP TABLE IF EXISTS {{product}};\n",
    "\n",
    "CREATE TABLE {{product}} AS\n",
    "SELECT * FROM {{upstream['clean']}}\n",
    "WHERE x > 10\n",
    "```\n",
    "\n",
    "The `{% set .. %}` statement defines a `product` variable, this serves two purposes. First, it tells Ploomber that this script is going to create a table named `my_table` in a schema named `my_schema`, for any script that declares the current script as upstream dependency, Ploomber will pass this information so it can use it as input. Second, it allows us to declare the value once and re-use it in two places via the `{{product}}` placeholder.\n",
    "\n",
    "If you modify this script and re-execute your pipeline, you'd want to overwrite any existing table, this is why we have the `DROP TABLE IF EXISTS ...;` statement before `CREATE TABLE ..;`, since both of them take the table name as argument, we can use the `{{product}}` placeholder.\n",
    "\n",
    "Finally, the `{{upstream['clean']}}` placeholders tells Ploomber that the current script uses the product from a task named `clean` as input data. This defines the dependency relationship between these two scripts and also implies that the placeholder will be replaced by the actual table/view generated by the `clean` task.\n",
    "\n",
    "These are the basic elements for templated SQL scripts, you don't have to use more if you don't want to but sometimes is convenient to do so to write concise code and maximize reusability.\n",
    "\n",
    "## Control structures\n",
    "\n",
    "jinja offers control structures that help us write SQL code on the fly. Say we want to compute summary statistics on a given column:\n",
    "\n",
    "```postgresql\n",
    "SELECT\n",
    "    some_column,\n",
    "    AVG(another_column) as avg_another_column,\n",
    "    STDEV(another_column) as stdev_another_column,\n",
    "    COUNT(another_column) as count_another_column,\n",
    "    SUM(another_column) as sum_another_column,\n",
    "    MAX(another_column) as max_another_column,\n",
    "    MIN(another_column) as min_another_column,\n",
    "FROM some_table\n",
    "GROUP BY some_column\n",
    "```\n",
    "\n",
    "This code is very repetitive, now imagine how repetitive. We can generate the same code succinctly using a for loop:\n",
    "\n",
    "```postgresql\n",
    "SELECT\n",
    "    some_column,\n",
    "-- loop over aggregation functions\n",
    "{% for fn in ['AVG', 'STDEV', 'COUNT', 'SUM', 'MAX', 'MIN'] %}\n",
    "    -- apply function to the column, name the column\n",
    "    -- and only add a comma if we are not in the last loop element\n",
    "    {{fn}}({{col_agg}}) as {{fn}}_{{col_agg}}{{ ',' if not loop.last else '' }}\n",
    "{% endfor %}\n",
    "FROM some_table\n",
    "GROUP BY some_column\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.006796,
     "end_time": "2020-11-26T16:37:50.508994",
     "exception": false,
     "start_time": "2020-11-26T16:37:50.502198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Macros\n",
    "\n",
    "Macros let us to maximize SQL code reusability by defining snippets that we can \"import\" in other files. To define a macro, enclose your snippet between the  `{% macro MACRO_NAME %} ... {% endmacro %}` tags. Let's create a macro using our previous snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:37:50.528473Z",
     "iopub.status.busy": "2020-11-26T16:37:50.527852Z",
     "iopub.status.idle": "2020-11-26T16:37:51.697381Z",
     "shell.execute_reply": "2020-11-26T16:37:51.697865Z"
    },
    "papermill": {
     "duration": 1.182159,
     "end_time": "2020-11-26T16:37:51.698176",
     "exception": false,
     "start_time": "2020-11-26T16:37:50.516017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ploomberutils import display_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:37:51.715381Z",
     "iopub.status.busy": "2020-11-26T16:37:51.714546Z",
     "iopub.status.idle": "2020-11-26T16:37:51.723606Z",
     "shell.execute_reply": "2020-11-26T16:37:51.724122Z"
    },
    "papermill": {
     "duration": 0.01972,
     "end_time": "2020-11-26T16:37:51.724351",
     "exception": false,
     "start_time": "2020-11-26T16:37:51.704631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "```postgresql\n",
       "{% macro agg(col_group, col_agg, from_table) -%}\n",
       "\n",
       "SELECT\n",
       "    {{col_group}},\n",
       "{% for fn in ['AVG', 'STDEV', 'COUNT', 'SUM', 'MAX', 'MIN'] %}\n",
       "    {{fn}}({{col_agg}}) as {{fn}}_{{col_agg}}{{ ',' if not loop.last else '' }}\n",
       "{% endfor %}\n",
       "FROM {{from_table}}\n",
       "GROUP BY {{col_group}}\n",
       "\n",
       "{%- endmacro %}\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_file('sql/macros.sql')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007201,
     "end_time": "2020-11-26T16:37:51.738253",
     "exception": false,
     "start_time": "2020-11-26T16:37:51.731052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The `{% macro %}` tag defines the macro name and parameters (if any). To use our macro in a different file, we have to import it. Let's say we define the previous macro in a `macros.sql` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:37:51.756275Z",
     "iopub.status.busy": "2020-11-26T16:37:51.755336Z",
     "iopub.status.idle": "2020-11-26T16:37:51.759297Z",
     "shell.execute_reply": "2020-11-26T16:37:51.758801Z"
    },
    "papermill": {
     "duration": 0.014886,
     "end_time": "2020-11-26T16:37:51.759499",
     "exception": false,
     "start_time": "2020-11-26T16:37:51.744613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "```postgresql\n",
       "-- import macros\n",
       "{% import \"macros.sql\" as m %}\n",
       "\n",
       "DROP TABLE IF EXISTS {{product}};\n",
       "\n",
       "CREATE TABLE {{product}} AS\n",
       "-- use macro\n",
       "{{m.agg(col_group='country', col_agg='price', from_table='sales')}}\n",
       "\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_file('sql/create-table.sql')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007096,
     "end_time": "2020-11-26T16:37:51.773535",
     "exception": false,
     "start_time": "2020-11-26T16:37:51.766439",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Configuring support for macros\n",
    "\n",
    "To work with macros, we have to make a small change to our `pipeline.yaml` file. So far, to specify which SQL files to use, we've just passed the path the file in the `source` key. To be able to import macros in our scripts we have to configure a source loader.\n",
    "\n",
    "A source loader is simply a folder with files, with a small addition: it defines an \"jinja environment\" that makes imports work (to know more about jinja environments, [click here](https://jinja.palletsprojects.com/en/2.11.x/api/#basics).\n",
    "\n",
    "Let's say all the scripts in our pipeline are in a `sql/` directory. `sql/` has two scripts, which correspond to the files shown in the previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:37:51.795094Z",
     "iopub.status.busy": "2020-11-26T16:37:51.794115Z",
     "iopub.status.idle": "2020-11-26T16:37:51.835318Z",
     "shell.execute_reply": "2020-11-26T16:37:51.835833Z"
    },
    "papermill": {
     "duration": 0.055492,
     "end_time": "2020-11-26T16:37:51.836073",
     "exception": false,
     "start_time": "2020-11-26T16:37:51.780581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql\n",
      "├── create-table.sql\n",
      "└── macros.sql\n",
      "\n",
      "0 directories, 2 files\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "tree sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007775,
     "end_time": "2020-11-26T16:37:51.851809",
     "exception": false,
     "start_time": "2020-11-26T16:37:51.844034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To configure our source loader. We just need to add a `source_loader` section like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:37:51.871981Z",
     "iopub.status.busy": "2020-11-26T16:37:51.871142Z",
     "iopub.status.idle": "2020-11-26T16:37:51.874989Z",
     "shell.execute_reply": "2020-11-26T16:37:51.875429Z"
    },
    "papermill": {
     "duration": 0.016059,
     "end_time": "2020-11-26T16:37:51.875674",
     "exception": false,
     "start_time": "2020-11-26T16:37:51.859615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "```yaml\n",
       "meta:\n",
       "  # initialize source loader\n",
       "  source_loader:\n",
       "    # use the sql/ folder as the \"root\" for loading files\n",
       "    path: sql/\n",
       "  \n",
       "  extract_upstream: False\n",
       "  extract_product: False\n",
       "\n",
       "tasks:\n",
       "  # sources are now loaded from the source loader, paths are relative\n",
       "  # to the source loader root directory\n",
       "  - source: create-table.sql\n",
       "    name: sql-task\n",
       "    product: [some_table, table]\n",
       "    client: db.get_client\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_file('pipeline.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.007446,
     "end_time": "2020-11-26T16:37:51.891088",
     "exception": false,
     "start_time": "2020-11-26T16:37:51.883642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Printing rendered code\n",
    "\n",
    "Templated SQL help us write more concise SQL code, but if your template renders to an invalid SQL script, you'll get syntax errors, only use it when the benefits outweigh this risk. One way to debug SQL templates is to see how the rendered code looks like, you can do so from the command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T16:37:51.910242Z",
     "iopub.status.busy": "2020-11-26T16:37:51.909645Z",
     "iopub.status.idle": "2020-11-26T16:37:54.239687Z",
     "shell.execute_reply": "2020-11-26T16:37:54.240453Z"
    },
    "papermill": {
     "duration": 2.3421,
     "end_time": "2020-11-26T16:37:54.240689",
     "exception": false,
     "start_time": "2020-11-26T16:37:51.898589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- import macros\n",
      "\n",
      "\n",
      "DROP TABLE IF EXISTS some_table;\n",
      "\n",
      "CREATE TABLE some_table AS\n",
      "-- use macro\n",
      "SELECT\n",
      "    country,\n",
      "\n",
      "    AVG(price) as AVG_price,\n",
      "\n",
      "    STDEV(price) as STDEV_price,\n",
      "\n",
      "    COUNT(price) as COUNT_price,\n",
      "\n",
      "    SUM(price) as SUM_price,\n",
      "\n",
      "    MAX(price) as MAX_price,\n",
      "\n",
      "    MIN(price) as MIN_price\n",
      "\n",
      "FROM sales\n",
      "GROUP BY country\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2428.66it/s]\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "ploomber task sql-task --source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.008311,
     "end_time": "2020-11-26T16:37:54.257585",
     "exception": false,
     "start_time": "2020-11-26T16:37:54.249274",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As we can see, our template is generating a valid SQL script. But if it didn't it'd be easier to spot errors in the rendered code than in the templated source.\n",
    "\n",
    "## Where to go next\n",
    "\n",
    "* [Jinja documentation](https://jinja.palletsprojects.com/en/2.11.x/templates/)\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.030128,
   "end_time": "2020-11-26T16:37:55.684773",
   "environment_variables": {},
   "exception": null,
   "input_path": "/var/folders/3h/_lvh_w_x5g30rrjzb_xnn2j80000gq/T/tmpq14yk4k_.ipynb",
   "output_path": "../../projects-ploomber/sql-templating/README.ipynb",
   "parameters": {
    "product": "../../projects-ploomber/sql-templating/README.ipynb"
   },
   "start_time": "2020-11-26T16:37:49.654645",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
